---
title: Enabling an External Blobstore
owner: BBR
---

This topic describes how to enable an external blobstore so that it can be backed up
and restored by BOSH Backup and Restore (BBR). 

If your external blobstore is hosted on Amazon S3 or a compatible storage solution that supports S3 versioning,
`cf-deployment` provides support for it to be backed up and restored by BBR.<br>
OR<br>
If your external blobstore is hosted on Amazon S3 or a compatible storage solution that supports S3 versioning, 
it can be backed up and restored by BBR.

The backup artifact only contains references to versions of blobs, not the actual files.
As a consequence, **restores only work if the original bucket still exists**.
If the bucket gets deleted, all its versions are deleted with it,
and you cannot restore it unless you have a replica. 
For how to restore from a replica, see [Restore from Replicas](#restore-from-replicas) below.


## <a id="enable-versioning"></a> Enable Versioning on Your External Blobstore

BBR only supports the backup and restore of blobstores stored in versioned, S3-compatible buckets.

To enable versioning of S3 buckets, do the following:

1. Follow the instructions in the Amazon S3 documentation, [How Do I Enable or Suspend Versioning for an S3 Bucket?]
(https://docs.aws.amazon.com/AmazonS3/latest/user-guide/enable-versioning.html)
to enable versioning. 

2. If your blobstore buckets are not empty, run the following command on each one of them, using the
[AWS CLI](https://aws.amazon.com/cli/):

    <code>aws s3 cp s3://BUCKET-NAME/ s3://BUCKET-NAME/ --recursive --metadata bump=true</code>

    <pre class="terminal">
    $ aws s3 cp s3://my-bucket/ s3://my-bucket/ --recursive --metadata bump=true
    </pre>
 
    This makes sure that each file in your buckets has a valid version ID.

**Questions**
1. What do I do if I have a non-S3 but compatible bucket? <br>
2. Do we have a sample output from the aws s3 command. 


## <a id="enable-backup-and-restore"></a> Enable Backup and Restore of External Blobstores

To backup a Cloud Foundry deployment that uses an S3-compatible blobstore, do the following:

1. Colocate the `s3-versioned-blobstore-backup-restorer` job from the
[`backup-and-restore-sdk-release`](https://github.com/cloudfoundry-incubator/backup-and-restore-sdk-release/tree/master)
as part of your deployment.

2. If you are using [`cf-deployment`](https://github.com/cloudfoundry/cf-deployment), 
   include the `enable-backup-restore-s3.yml` ops file in your deployment.

    <p class="note"> You should apply <code>enable-backup-restore.yml</code> and <code>use-s3-blobstore.yml</code>
       before <code>enable-backup-restore-s3.yml</code>
       See <a href="cf-backup.html#order">Apply Ops Files in the Correct Order</a>.</p>

    Even if you do not use `cf-deployment`, review the ops file for examples of how to configure the job.

## <a id="supported-restore-scenarios"></a> Supported Restore Scenarios

There are three distinct restore scenarios:

+ [In-Place Restore](#in-place-restore)
+ [Restore to New Buckets](#restore-to-new-buckets)
+ [Restore from Replicas](#restore-from-replicas)

### <a id="in-place-restore"></a> In-Place Restore
When backing up an
external blobstore, the backup consists of a snapshot of the objects' ids and versions.
If your destination Cloud Foundry for a restore uses the original buckets of the backed-up Cloud Foundry (i.e. you
are doing an in-place restore), then during a restore
those versions are retrieved and set to be the current versions in the buckets.

### <a id="restore-to-new-buckets"></a> Restore to New Buckets

If your destination Cloud Foundry for a restore uses different buckets then you can also restore into
those buckets, provided the original buckets still exist. During restore the original versions are copied from the
original buckets to the destination buckets.

The destination buckets must be versioned. **Any files in the destination buckets that are not in the
backup artifact will be deleted.**

Ensure that the `s3-versioned-blobstore-backup-restorer` job is configured to point to the
destination buckets, and then run the `bbr` `restore` command.

### <a id="restore-from-replicas"></a> Restore from replicas

To protect yourself from losing your blobstore buckets, you might set up [Cross-Region Replication](https://docs.aws.amazon.com/AmazonS3/latest/dev/crr.html). Replication results in buckets that are identical to the original ones, including their version IDs. This will allow you to perform restores from the replicas, in case your original buckets are lost.

To do so, you will need to modify your backup artifacts to point to the replicas:

- move into the backup artifact directory
- extract the blobstore backup archive:

```
tar xvf backup-restore-0-s3-versioned-blobstore-backup-restorer.tar
```

- modify the `blobstore.json` to point to the replicated buckets
- recalculate the shasum of `blobstore.json`

```
shasum -a 256 blobstore.json
```

- update the metadata file entry for that `blobstore.json` with the new checksum.

- recreate the archive

```
tar cvf backup-restore-0-s3-versioned-blobstore-backup-restorer.tar blobstore.json
```

The backup artifact is now ready to be restored from the replicated buckets.
